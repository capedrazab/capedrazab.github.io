{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cuda_class1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVcZtD2Wga9_",
        "outputId": "a323239b-ecfd-4f60-9dc8-278c5fba6122"
      },
      "source": [
        "%cd /usr/local/cuda-11.0/samples/1_Utilities/deviceQuery\n",
        "!make\n",
        "!./deviceQuery"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-11.0/samples/1_Utilities/deviceQuery\n",
            "/usr/local/cuda-11.0/bin/nvcc -ccbin g++ -I../../common/inc  -m64    -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_80,code=compute_80 -o deviceQuery.o -c deviceQuery.cpp\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "/usr/local/cuda-11.0/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_80,code=compute_80 -o deviceQuery deviceQuery.o \n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "mkdir -p ../../bin/x86_64/linux/release\n",
            "cp deviceQuery ../../bin/x86_64/linux/release\n",
            "./deviceQuery Starting...\n",
            "\n",
            " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
            "\n",
            "Detected 1 CUDA Capable device(s)\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version / Runtime Version          11.2 / 11.0\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 15110 MBytes (15843721216 bytes)\n",
            "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
            "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
            "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
            "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of threads per block:           1024\n",
            "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
            "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Texture alignment:                             512 bytes\n",
            "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
            "  Run time limit on kernels:                     No\n",
            "  Integrated GPU sharing Host Memory:            No\n",
            "  Support host page-locked memory mapping:       Yes\n",
            "  Alignment requirement for Surfaces:            Yes\n",
            "  Device has ECC support:                        Enabled\n",
            "  Device supports Unified Addressing (UVA):      Yes\n",
            "  Device supports Managed Memory:                Yes\n",
            "  Device supports Compute Preemption:            Yes\n",
            "  Supports Cooperative Kernel Launch:            Yes\n",
            "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
            "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
            "  Compute Mode:\n",
            "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
            "\n",
            "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.2, CUDA Runtime Version = 11.0, NumDevs = 1\n",
            "Result = PASS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42EKwonsdjA7",
        "outputId": "a2c689e4-56ab-4d3a-b259-afb673f4dbe9"
      },
      "source": [
        "%ls /usr/local/cuda-11.0/samples/0_Simple/vectorAdd/\n",
        "%cd /usr/local/cuda-11.0/samples/0_Simple/vectorAdd/\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Makefile  NsightEclipse.xml  readme.txt  vectorAdd.cu\n",
            "/usr/local/cuda-11.0/samples/0_Simple/vectorAdd\n",
            "/usr/local/cuda-11.0/bin/nvcc -ccbin g++ -I../../common/inc  -m64    -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_80,code=compute_80 -o vectorAdd.o -c vectorAdd.cu\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "/usr/local/cuda-11.0/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_80,code=compute_80 -o vectorAdd vectorAdd.o \n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "mkdir -p ../../bin/x86_64/linux/release\n",
            "cp vectorAdd ../../bin/x86_64/linux/release\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3swWDWpfgPuQ",
        "outputId": "219b7e89-6d07-4c6a-9c24-a027bd1a0690"
      },
      "source": [
        "!./vectorAdd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Vector addition of 50000 elements]\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 196 blocks of 256 threads\n",
            "Copy output data from the CUDA device to the host memory\n",
            "Test PASSED\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWATyReLpXI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac2437b-4ade-43e7-d96d-860188faac7d"
      },
      "source": [
        "#@title cuda Install\n",
        "!echo CUDA AND NVIDIA INSTALLATION\n",
        "!echo NOTE: THERE IS A QUESTION IN THE INSTALLATION, PLEASE DO NOT FORGET TO ANSWER IT (YOU CAN CHOOSE Y)\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb;\n",
        "!dpkg -i cuda-repo-ubuntu1604_8.0.61-1_amd64.deb;\n",
        "!apt-get update -qq;\n",
        "!apt-get install cuda-8.0;\n",
        "!ln -sf /usr/local/cuda-8.0 /usr/local/cuda\n",
        "import os\n",
        "os.environ['PATH'] += ':/usr/local/cuda/bin'\n",
        "os.environ['LD_LIBRARY_PATH'] += ':/usr/local/cuda/lib'\n",
        "\n",
        "!apt-get install gcc-5 g++-5 -y -qq;\n",
        "!ln -s /usr/bin/gcc-5 /usr/local/cuda/bin/gcc;\n",
        "!ln -s /usr/bin/g++-5 /usr/local/cuda/bin/g++;\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA AND NVIDIA INSTALLATION\n",
            "/bin/bash: -c: line 0: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 0: `echo NOTE: THERE IS A QUESTION IN THE INSTALLATION, PLEASE DO NOT FORGET TO ANSWER IT (YOU CAN CHOOSE Y)'\n",
            "--2021-06-25 21:46:23--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2690 (2.6K) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1604_8.0.61-1_amd64.deb.5’\n",
            "\n",
            "cuda-repo-ubuntu160 100%[===================>]   2.63K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-25 21:46:23 (169 MB/s) - ‘cuda-repo-ubuntu1604_8.0.61-1_amd64.deb.5’ saved [2690/2690]\n",
            "\n",
            "(Reading database ... 160775 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1604_8.0.61-1_amd64.deb ...\n",
            "Unpacking cuda-repo-ubuntu1604 (8.0.61-1) over (8.0.61-1) ...\n",
            "Setting up cuda-repo-ubuntu1604 (8.0.61-1) ...\n",
            "\n",
            "Configuration file '/etc/apt/sources.list.d/cuda.list'\n",
            " ==> File on system created by you or by a script.\n",
            " ==> File also in package provided by package maintainer.\n",
            "   What would you like to do about it ?  Your options are:\n",
            "    Y or I  : install the package maintainer's version\n",
            "    N or O  : keep your currently-installed version\n",
            "      D     : show the differences between the versions\n",
            "      Z     : start a shell to examine the situation\n",
            " The default action is to keep your current version.\n",
            "*** cuda.list (Y/I/N/O/D/Z) [default=N] ? ^C\n",
            "^C\n",
            "E: dpkg was interrupted, you must manually run 'dpkg --configure -a' to correct the problem. \n",
            "E: dpkg was interrupted, you must manually run 'dpkg --configure -a' to correct the problem. \n",
            "ln: failed to create symbolic link '/usr/local/cuda/bin/gcc': File exists\n",
            "ln: failed to create symbolic link '/usr/local/cuda/bin/g++': File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKAzpoH7GikQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc2bfe6-97ed-4be4-bf0d-4e9c039ce9c1"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-j4z9l744\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-j4z9l744\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=ef640296fa3a02eddd90e451e298959d1695315d2761bcfe2ca3602d4b9179f4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-52bxdmfg/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxdiA9ieuMhw",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7a2c2d3-915d-43e0-b488-0b0818691b46"
      },
      "source": [
        "#@title  Hello world\n",
        "%%cu\n",
        "#include <iostream>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "int main() {\n",
        "    std::cout << \"Hello world!\";\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello world!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoUY_-cCbxxZ"
      },
      "source": [
        "%ls /usr/local/cuda-10.1/samples/common/inc\n",
        "!cat /usr/local/cuda-10.1/samples/0_Simple/vectorAdd/Makefile\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61KyjX_viioI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "d2e610e4-ddb7-4590-ed5e-e558bbe44226"
      },
      "source": [
        "%cd /usr/local/cuda-10.1/samples/0_Simple/vectorAdd/\n",
        "!make\n",
        "!./vectorAdd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-10.1/samples/0_Simple/vectorAdd\n",
            "/usr/local/cuda-10.1/bin/nvcc -ccbin g++ -I../../common/inc  -m64    -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o vectorAdd.o -c vectorAdd.cu\n",
            "/usr/local/cuda-10.1/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o vectorAdd vectorAdd.o \n",
            "mkdir -p ../../bin/x86_64/linux/release\n",
            "cp vectorAdd ../../bin/x86_64/linux/release\n",
            "[Vector addition of 50000 elements]\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 196 blocks of 256 threads\n",
            "Copy output data from the CUDA device to the host memory\n",
            "Test PASSED\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InhgJNkFJVPQ",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3b8509-5d86-42aa-d95d-d20dfede1e2a"
      },
      "source": [
        "#@title vector add\n",
        "\n",
        "%%cu\n",
        "/************* add vector ******************************************************/\n",
        "#include <stdio.h>\n",
        "// For the CUDA runtime routines (prefixed with \"cuda_\")\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "  \n",
        "/*******************************************************************************/\n",
        "\n",
        "__global__ void\n",
        "vectorAdd(const float *A, const float *B, float *C, int numElements)\n",
        "{\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    if (i < numElements)\n",
        "    {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "/*******************************************************************************/\n",
        "int main(void)\n",
        "{\n",
        "    // Error code to check return values for CUDA calls\n",
        "    cudaError_t err = cudaSuccess;\n",
        "\n",
        "    // Print the vector length to be used, and compute its size\n",
        "    int numElements = 50000;\n",
        "    size_t size = numElements * sizeof(float);\n",
        "    printf(\"[Vector addition of %d elements]\\n\", numElements);\n",
        "\n",
        "    // Allocate the host input vector A\n",
        "    float *h_A = (float *)malloc(size);\n",
        "\n",
        "    // Allocate the host input vector B\n",
        "    float *h_B = (float *)malloc(size);\n",
        "\n",
        "    // Allocate the host output vector C\n",
        "    float *h_C = (float *)malloc(size);\n",
        "\n",
        "    // Verify that allocations succeeded\n",
        "    if (h_A == NULL || h_B == NULL || h_C == NULL)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Initialize the host input vectors\n",
        "    for (int i = 0; i < numElements; ++i)\n",
        "    {\n",
        "        h_A[i] = rand()/(float)RAND_MAX;\n",
        "        h_B[i] = rand()/(float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Allocate the device input vector A\n",
        "    float *d_A = NULL;\n",
        "    err = cudaMalloc((void **)&d_A, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Allocate the device input vector B\n",
        "    float *d_B = NULL;\n",
        "    err = cudaMalloc((void **)&d_B, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Allocate the device output vector C\n",
        "    float *d_C = NULL;\n",
        "    err = cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Copy the host input vectors A and B in host memory to the device input vectors in\n",
        "    // device memory\n",
        "    printf(\"Copy input data from the host memory to the CUDA device\\n\");\n",
        "    err = cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector A from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    err = cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector B from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Launch the Vector Add CUDA Kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid =(numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock);\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);\n",
        "    err = cudaGetLastError();\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to launch vectorAdd kernel (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Copy the device result vector in device memory to the host result vector\n",
        "    // in host memory.\n",
        "    printf(\"Copy output data from the CUDA device to the host memory\\n\");\n",
        "    err = cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Verify that the result vector is correct\n",
        "    for (int i = 0; i < numElements; ++i)\n",
        "    {\n",
        "        if (fabs(h_A[i] + h_B[i] - h_C[i]) > 1e-5)\n",
        "        {\n",
        "            fprintf(stderr, \"Result verification failed at element %d!\\n\", i);\n",
        "            exit(EXIT_FAILURE);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Free device global memory\n",
        "    err = cudaFree(d_A);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    err = cudaFree(d_B);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    err = cudaFree(d_C);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    // Reset the device and exit\n",
        "    err = cudaDeviceReset();\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to deinitialize the device! error=%s\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    printf(\"Done\\n\");\n",
        "    return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Vector addition of 50000 elements]\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 196 blocks of 256 threads\n",
            "Copy output data from the CUDA device to the host memory\n",
            "Done\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWYeug39k-iI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g57FHZIlG6UZ",
        "cellView": "form"
      },
      "source": [
        "#@title pi\n",
        "%%cu\n",
        "/****** calculate pi *******/\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "// For the CUDA runtime routines (prefixed with \"cuda_\")\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define BLOCKSPERGRID  512\n",
        "#define NUMTHREADS 8192\n",
        "#define ITERATIONS 16e09\n",
        "\n",
        "/*****************************************************************************\n",
        "/*kernel\n",
        "*****************************************************************************/\n",
        "\n",
        "\n",
        "__global__ void calculatePi(double *piTotal, long int iterations, int totalThreads)\n",
        "{   long int initIteration, endIteration;\n",
        "    long int i = 0;\n",
        "    double piPartial;\n",
        "    \n",
        "    int index = (blockDim.x * blockIdx.x) + threadIdx.x;\n",
        "\n",
        "    initIteration = (iterations/totalThreads) * index;\n",
        "    endIteration = initIteration + (iterations/totalThreads) - 1;\n",
        "    \n",
        "    i = initIteration;\n",
        "    piPartial = 0;\n",
        "    \n",
        "    do{\n",
        "        piPartial = piPartial + (double)(4.0 / ((i*2)+1));\n",
        "        i++;\n",
        "        piPartial = piPartial - (double)(4.0 / ((i*2)+1));\n",
        "        i++;\n",
        "    }while(i < endIteration);\n",
        "\n",
        "    piTotal[index] = piPartial;\n",
        "    \n",
        "    __syncthreads();\n",
        "    if(index == 0){\n",
        "        for(i = 1; i < totalThreads; i++)\n",
        "            piTotal[0] = piTotal[0] + piTotal[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "/******************************************************************************/\n",
        "\n",
        "\n",
        "int main()\n",
        "{   \n",
        "    int blocksPerGrid, threadsPerBlock, i, size;\n",
        "    long int iterations;\n",
        "    int totalThreads;\n",
        "    double *h_pitotal, *d_pitotal;\n",
        "    \n",
        "    blocksPerGrid = BLOCKSPERGRID;\n",
        "    cudaError_t err = cudaSuccess;\n",
        "\n",
        "    size = sizeof(double)*NUMTHREADS;\n",
        "    h_pitotal = (double *)malloc(size);\n",
        "    if ( h_pitotal == NULL){\n",
        "        fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    \n",
        "    for(i = 0; i < NUMTHREADS; i++)\n",
        "        h_pitotal[i] = 0.0;\n",
        "\n",
        "    err = cudaMalloc((void **)&d_pitotal, size);\n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to allocate device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    \n",
        "    err = cudaMemcpy(d_pitotal, h_pitotal, sizeof(double)*NUMTHREADS, cudaMemcpyHostToDevice);\n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Lanzar KERNEL\n",
        "    threadsPerBlock = NUMTHREADS/blocksPerGrid;\n",
        "    totalThreads = blocksPerGrid * threadsPerBlock;\n",
        "    iterations = ITERATIONS;\n",
        "    printf(\"CUDA kernel launch with %d blocks of %d threads Total: %i       \", blocksPerGrid, threadsPerBlock, totalThreads  );\n",
        "    calculatePi<<<blocksPerGrid, threadsPerBlock>>>(d_pitotal, iterations, totalThreads);\n",
        "    err = cudaGetLastError();\n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to launch vectorAdd kernel (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    err = cudaMemcpy(h_pitotal, d_pitotal, size, cudaMemcpyDeviceToHost);\n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    err = cudaFree(d_pitotal);\n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to free device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    printf(\"Calculated pi: %.12f\", *h_pitotal);\n",
        "    // Free host memory\n",
        "\n",
        "    free(h_pitotal);\n",
        "    err = cudaDeviceReset();\n",
        "    if (err != cudaSuccess){\n",
        "        fprintf(stderr, \"Failed to deinitialize the device! error=%s\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvdJgP_jmelJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c3b626-7e5a-4b7e-f7be-f038fe930105"
      },
      "source": [
        "%ls /usr/local/cuda-10.1/samples/1_Utilities/deviceQuery/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deviceQuery.cpp  Makefile  NsightEclipse.xml  readme.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI7QQVXftsBv"
      },
      "source": [
        "#@title deviceQuery\n",
        "!echo NVIDIA CUDA AND DRIVES VERIFICATION\n",
        "%cd /usr/local/cuda/samples/1_Utilities/deviceQuery/\n",
        "!ls\n",
        "!make\n",
        "!./deviceQuery\n",
        "!nvcc --version\n",
        "%cat /usr/local/cuda/samples/1_Utilities/deviceQuery/deviceQuery.cpp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpV8I2N1lg--"
      },
      "source": [
        "%cat /usr/local/cuda/samples/0_Simple/vectorAdd/Makefile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zosrehJeVQ63",
        "cellView": "form"
      },
      "source": [
        "#@title deviceQuery_code\n",
        "%%cu\n",
        "\n",
        "/*\n",
        " * Copyright 1993-2015 NVIDIA Corporation.  All rights reserved.\n",
        " *\n",
        " * Please refer to the NVIDIA end user license agreement (EULA) associated\n",
        " * with this source code for terms and conditions that govern your use of\n",
        " * this software. Any use, reproduction, disclosure, or distribution of\n",
        " * this software and related documentation outside the terms of the EULA\n",
        " * is strictly prohibited.\n",
        " *\n",
        " */\n",
        "/* This sample queries the properties of the CUDA devices present in the system via CUDA Runtime API. */\n",
        "\n",
        "// Shared Utilities (QA Testing)\n",
        "\n",
        "// std::system includes\n",
        "#include <memory>\n",
        "#include <iostream>\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include </usr/local/cuda/samples/common/inc/helper_cuda.h>\n",
        "\n",
        "\n",
        "\n",
        "int *pArgc = NULL;\n",
        "char **pArgv = NULL;\n",
        "\n",
        "#if CUDART_VERSION < 5000\n",
        "\n",
        "// CUDA-C includes\n",
        "#include <cuda.h>\n",
        "\n",
        "// This function wraps the CUDA Driver API into a template function\n",
        "template <class T>\n",
        "inline void getCudaAttribute(T *attribute, CUdevice_attribute device_attribute, int device)\n",
        "{\n",
        "    CUresult error =    cuDeviceGetAttribute(attribute, device_attribute, device);\n",
        "\n",
        "    if (CUDA_SUCCESS != error)\n",
        "    {\n",
        "        fprintf(stderr, \"cuSafeCallNoSync() Driver API error = %04d from file <%s>, line %i.\\n\",\n",
        "                error, __FILE__, __LINE__);\n",
        "\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "}\n",
        "\n",
        "#endif /* CUDART_VERSION < 5000 */\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////////////\n",
        "// Program main\n",
        "////////////////////////////////////////////////////////////////////////////////\n",
        "int\n",
        "main(int argc, char **argv)\n",
        "{\n",
        "    pArgc = &argc;\n",
        "    pArgv = argv;\n",
        "\n",
        "    printf(\"%s Starting...\\n\\n\", argv[0]);\n",
        "    printf(\" CUDA Device Query (Runtime API) version (CUDART static linking)\\n\\n\");\n",
        "\n",
        "    int deviceCount = 0;\n",
        "    cudaError_t error_id = cudaGetDeviceCount(&deviceCount);\n",
        "\n",
        "    if (error_id != cudaSuccess)\n",
        "    {\n",
        "        printf(\"cudaGetDeviceCount returned %d\\n-> %s\\n\", (int)error_id, cudaGetErrorString(error_id));\n",
        "        printf(\"Result = FAIL\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // This function call returns 0 if there are no CUDA capable devices.\n",
        "    if (deviceCount == 0)\n",
        "    {\n",
        "        printf(\"There are no available device(s) that support CUDA\\n\");\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        printf(\"Detected %d CUDA Capable device(s)\\n\", deviceCount);\n",
        "    }\n",
        "\n",
        "    int dev, driverVersion = 0, runtimeVersion = 0;\n",
        "\n",
        "    for (dev = 0; dev < deviceCount; ++dev)\n",
        "    {\n",
        "        cudaSetDevice(dev);\n",
        "        cudaDeviceProp deviceProp;\n",
        "        cudaGetDeviceProperties(&deviceProp, dev);\n",
        "\n",
        "        printf(\"\\nDevice %d: \\\"%s\\\"\\n\", dev, deviceProp.name);\n",
        "\n",
        "        // Console log\n",
        "        cudaDriverGetVersion(&driverVersion);\n",
        "        cudaRuntimeGetVersion(&runtimeVersion);\n",
        "        printf(\"  CUDA Driver Version / Runtime Version          %d.%d / %d.%d\\n\", driverVersion/1000, (driverVersion%100)/10, runtimeVersion/1000, (runtimeVersion%100)/10);\n",
        "        printf(\"  CUDA Capability Major/Minor version number:    %d.%d\\n\", deviceProp.major, deviceProp.minor);\n",
        "\n",
        "        char msg[256];\n",
        "        SPRINTF(msg, \"  Total amount of global memory:                 %.0f MBytes (%llu bytes)\\n\",\n",
        "                (float)deviceProp.totalGlobalMem/1048576.0f, (unsigned long long) deviceProp.totalGlobalMem);\n",
        "        printf(\"%s\", msg);\n",
        "\n",
        "        printf(\"  (%2d) Multiprocessors, (%3d) CUDA Cores/MP:     %d CUDA Cores\\n\",\n",
        "               deviceProp.multiProcessorCount,\n",
        "               _ConvertSMVer2Cores(deviceProp.major, deviceProp.minor),\n",
        "               _ConvertSMVer2Cores(deviceProp.major, deviceProp.minor) * deviceProp.multiProcessorCount);\n",
        "        printf(\"  GPU Max Clock rate:                            %.0f MHz (%0.2f GHz)\\n\", deviceProp.clockRate * 1e-3f, deviceProp.clockRate * 1e-6f);\n",
        "\n",
        "\n",
        "#if CUDART_VERSION >= 5000\n",
        "        // This is supported in CUDA 5.0 (runtime API device properties)\n",
        "        printf(\"  Memory Clock rate:                             %.0f Mhz\\n\", deviceProp.memoryClockRate * 1e-3f);\n",
        "        printf(\"  Memory Bus Width:                              %d-bit\\n\",   deviceProp.memoryBusWidth);\n",
        "\n",
        "        if (deviceProp.l2CacheSize)\n",
        "        {\n",
        "            printf(\"  L2 Cache Size:                                 %d bytes\\n\", deviceProp.l2CacheSize);\n",
        "        }\n",
        "\n",
        "#else\n",
        "        // This only available in CUDA 4.0-4.2 (but these were only exposed in the CUDA Driver API)\n",
        "        int memoryClock;\n",
        "        getCudaAttribute<int>(&memoryClock, CU_DEVICE_ATTRIBUTE_MEMORY_CLOCK_RATE, dev);\n",
        "        printf(\"  Memory Clock rate:                             %.0f Mhz\\n\", memoryClock * 1e-3f);\n",
        "        int memBusWidth;\n",
        "        getCudaAttribute<int>(&memBusWidth, CU_DEVICE_ATTRIBUTE_GLOBAL_MEMORY_BUS_WIDTH, dev);\n",
        "        printf(\"  Memory Bus Width:                              %d-bit\\n\", memBusWidth);\n",
        "        int L2CacheSize;\n",
        "        getCudaAttribute<int>(&L2CacheSize, CU_DEVICE_ATTRIBUTE_L2_CACHE_SIZE, dev);\n",
        "\n",
        "        if (L2CacheSize)\n",
        "        {\n",
        "            printf(\"  L2 Cache Size:                                 %d bytes\\n\", L2CacheSize);\n",
        "        }\n",
        "\n",
        "#endif\n",
        "\n",
        "        printf(\"  Maximum Texture Dimension Size (x,y,z)         1D=(%d), 2D=(%d, %d), 3D=(%d, %d, %d)\\n\",\n",
        "               deviceProp.maxTexture1D   , deviceProp.maxTexture2D[0], deviceProp.maxTexture2D[1],\n",
        "               deviceProp.maxTexture3D[0], deviceProp.maxTexture3D[1], deviceProp.maxTexture3D[2]);\n",
        "        printf(\"  Maximum Layered 1D Texture Size, (num) layers  1D=(%d), %d layers\\n\",\n",
        "               deviceProp.maxTexture1DLayered[0], deviceProp.maxTexture1DLayered[1]);\n",
        "        printf(\"  Maximum Layered 2D Texture Size, (num) layers  2D=(%d, %d), %d layers\\n\",\n",
        "               deviceProp.maxTexture2DLayered[0], deviceProp.maxTexture2DLayered[1], deviceProp.maxTexture2DLayered[2]);\n",
        "\n",
        "\n",
        "        printf(\"  Total amount of constant memory:               %lu bytes\\n\", deviceProp.totalConstMem);\n",
        "        printf(\"  Total amount of shared memory per block:       %lu bytes\\n\", deviceProp.sharedMemPerBlock);\n",
        "        printf(\"  Total number of registers available per block: %d\\n\", deviceProp.regsPerBlock);\n",
        "        printf(\"  Warp size:                                     %d\\n\", deviceProp.warpSize);\n",
        "        printf(\"  Maximum number of threads per multiprocessor:  %d\\n\", deviceProp.maxThreadsPerMultiProcessor);\n",
        "        printf(\"  Maximum number of threads per block:           %d\\n\", deviceProp.maxThreadsPerBlock);\n",
        "        printf(\"  Max dimension size of a thread block (x,y,z): (%d, %d, %d)\\n\",\n",
        "               deviceProp.maxThreadsDim[0],\n",
        "               deviceProp.maxThreadsDim[1],\n",
        "               deviceProp.maxThreadsDim[2]);\n",
        "        printf(\"  Max dimension size of a grid size    (x,y,z): (%d, %d, %d)\\n\",\n",
        "               deviceProp.maxGridSize[0],\n",
        "               deviceProp.maxGridSize[1],\n",
        "               deviceProp.maxGridSize[2]);\n",
        "        printf(\"  Maximum memory pitch:                          %lu bytes\\n\", deviceProp.memPitch);\n",
        "        printf(\"  Texture alignment:                             %lu bytes\\n\", deviceProp.textureAlignment);\n",
        "        printf(\"  Concurrent copy and kernel execution:          %s with %d copy engine(s)\\n\", (deviceProp.deviceOverlap ? \"Yes\" : \"No\"), deviceProp.asyncEngineCount);\n",
        "        printf(\"  Run time limit on kernels:                     %s\\n\", deviceProp.kernelExecTimeoutEnabled ? \"Yes\" : \"No\");\n",
        "        printf(\"  Integrated GPU sharing Host Memory:            %s\\n\", deviceProp.integrated ? \"Yes\" : \"No\");\n",
        "        printf(\"  Support host page-locked memory mapping:       %s\\n\", deviceProp.canMapHostMemory ? \"Yes\" : \"No\");\n",
        "        printf(\"  Alignment requirement for Surfaces:            %s\\n\", deviceProp.surfaceAlignment ? \"Yes\" : \"No\");\n",
        "        printf(\"  Device has ECC support:                        %s\\n\", deviceProp.ECCEnabled ? \"Enabled\" : \"Disabled\");\n",
        "#if defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)\n",
        "        printf(\"  CUDA Device Driver Mode (TCC or WDDM):         %s\\n\", deviceProp.tccDriver ? \"TCC (Tesla Compute Cluster Driver)\" : \"WDDM (Windows Display Driver Model)\");\n",
        "#endif\n",
        "        printf(\"  Device supports Unified Addressing (UVA):      %s\\n\", deviceProp.unifiedAddressing ? \"Yes\" : \"No\");\n",
        "        printf(\"  Device PCI Domain ID / Bus ID / location ID:   %d / %d / %d\\n\", deviceProp.pciDomainID, deviceProp.pciBusID, deviceProp.pciDeviceID);\n",
        "\n",
        "        const char *sComputeMode[] =\n",
        "        {\n",
        "            \"Default (multiple host threads can use ::cudaSetDevice() with device simultaneously)\",\n",
        "            \"Exclusive (only one host thread in one process is able to use ::cudaSetDevice() with this device)\",\n",
        "            \"Prohibited (no host thread can use ::cudaSetDevice() with this device)\",\n",
        "            \"Exclusive Process (many threads in one process is able to use ::cudaSetDevice() with this device)\",\n",
        "            \"Unknown\",\n",
        "            NULL\n",
        "        };\n",
        "        printf(\"  Compute Mode:\\n\");\n",
        "        printf(\"     < %s >\\n\", sComputeMode[deviceProp.computeMode]);\n",
        "    }\n",
        "\n",
        "    // If there are 2 or more GPUs, query to determine whether RDMA is supported\n",
        "    if (deviceCount >= 2)\n",
        "    {\n",
        "        cudaDeviceProp prop[64];\n",
        "        int gpuid[64]; // we want to find the first two GPUs that can support P2P\n",
        "        int gpu_p2p_count = 0;\n",
        "\n",
        "        for (int i=0; i < deviceCount; i++)\n",
        "        {\n",
        "            checkCudaErrors(cudaGetDeviceProperties(&prop[i], i));\n",
        "\n",
        "            // Only boards based on Fermi or later can support P2P\n",
        "            if ((prop[i].major >= 2)\n",
        "#if defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)\n",
        "                // on Windows (64-bit), the Tesla Compute Cluster driver for windows must be enabled to support this\n",
        "                && prop[i].tccDriver\n",
        "#endif\n",
        "               )\n",
        "            {\n",
        "                // This is an array of P2P capable GPUs\n",
        "                gpuid[gpu_p2p_count++] = i;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Show all the combinations of support P2P GPUs\n",
        "        int can_access_peer;\n",
        "\n",
        "        if (gpu_p2p_count >= 2)\n",
        "        {\n",
        "            for (int i = 0; i < gpu_p2p_count; i++)\n",
        "            {\n",
        "                for (int j = 0; j < gpu_p2p_count; j++)\n",
        "                {\n",
        "                    if (gpuid[i] == gpuid[j])\n",
        "                    {\n",
        "                        continue;\n",
        "                    }\n",
        "                    checkCudaErrors(cudaDeviceCanAccessPeer(&can_access_peer, gpuid[i], gpuid[j]));\n",
        "                        printf(\"> Peer access from %s (GPU%d) -> %s (GPU%d) : %s\\n\", prop[gpuid[i]].name, gpuid[i],\n",
        "                           prop[gpuid[j]].name, gpuid[j] ,\n",
        "                           can_access_peer ? \"Yes\" : \"No\");\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // csv masterlog info\n",
        "    // *****************************\n",
        "    // exe and CUDA driver name\n",
        "    printf(\"\\n\");\n",
        "    std::string sProfileString = \"deviceQuery, CUDA Driver = CUDART\";\n",
        "    char cTemp[16];\n",
        "\n",
        "    // driver version\n",
        "    sProfileString += \", CUDA Driver Version = \";\n",
        "#if defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)\n",
        "    sprintf_s(cTemp, 10, \"%d.%d\", driverVersion/1000, (driverVersion%100)/10);\n",
        "#else\n",
        "    sprintf(cTemp, \"%d.%d\", driverVersion/1000, (driverVersion%100)/10);\n",
        "#endif\n",
        "    sProfileString +=  cTemp;\n",
        "\n",
        "    // Runtime version\n",
        "    sProfileString += \", CUDA Runtime Version = \";\n",
        "#if defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)\n",
        "    sprintf_s(cTemp, 10, \"%d.%d\", runtimeVersion/1000, (runtimeVersion%100)/10);\n",
        "#else\n",
        "    sprintf(cTemp, \"%d.%d\", runtimeVersion/1000, (runtimeVersion%100)/10);\n",
        "#endif\n",
        "    sProfileString +=  cTemp;\n",
        "\n",
        "    // Device count\n",
        "    sProfileString += \", NumDevs = \";\n",
        "#if defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)\n",
        "    sprintf_s(cTemp, 10, \"%d\", deviceCount);\n",
        "#else\n",
        "    sprintf(cTemp, \"%d\", deviceCount);\n",
        "#endif\n",
        "    sProfileString += cTemp;\n",
        "\n",
        "    // Print Out all device Names\n",
        "    for (dev = 0; dev < deviceCount; ++dev)\n",
        "    {\n",
        "#if defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)\n",
        "        sprintf_s(cTemp, 13, \", Device%d = \", dev);\n",
        "#else\n",
        "        sprintf(cTemp, \", Device%d = \", dev);\n",
        "#endif\n",
        "        cudaDeviceProp deviceProp;\n",
        "        cudaGetDeviceProperties(&deviceProp, dev);\n",
        "        sProfileString += cTemp;\n",
        "        sProfileString += deviceProp.name;\n",
        "    }\n",
        "\n",
        "    sProfileString += \"\\n\";\n",
        "    printf(\"%s\", sProfileString.c_str());\n",
        "\n",
        "    printf(\"Result = PASS\\n\");\n",
        "\n",
        "    // finish\n",
        "    exit(EXIT_SUCCESS);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlluUW6UfV0l",
        "cellView": "form"
      },
      "source": [
        "#@title MatrixMult\n",
        "%%cu\n",
        "/************ matrix multiplication ************************/\n",
        "#include <stdio.h>\n",
        "// For the CUDA runtime routines (prefixed with \"cuda_\")\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define DIM  64\n",
        "#define XDIM  DIM\n",
        "#define YDIM  DIM\n",
        "#define MATRIXSIZE  XDIM*YDIM\n",
        "#define BLOCKSPERGRID  16\n",
        "#define NUMTHREADS DIM\n",
        "\n",
        "/*****************************************************************************/\n",
        "__global__ void\n",
        "multMatrix(const int *A, const int *B, int *C, int numElements)\n",
        "{\n",
        "\tint yOffset;\n",
        "    int i, x;\n",
        "    __shared__ int rowAshared[XDIM][32];\n",
        "\n",
        "    int y = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    int yRel = y - (blockDim.x * blockIdx.x);\n",
        "\n",
        "    yOffset = y * XDIM;\n",
        "    for(i = 0; i < XDIM; i++)\n",
        "        rowAshared[i][yRel] = *(A + yOffset + i);\n",
        "\n",
        "    if (y < numElements)\n",
        "    {\n",
        "        for(x = 0; x < XDIM; x++)\n",
        "        {   *(C + yOffset + x) = 0;\n",
        "            for(i = 0; i < XDIM; i++){\n",
        "                *(C + yOffset + x) = *(C + yOffset + x) + (rowAshared[i][yRel] * (*(B + (i*YDIM) + x )));\n",
        "            }\n",
        "        } \n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "/*****************************************************************************/\n",
        "\n",
        "int printMatrix(int *ap)\n",
        "{\n",
        "\tint x, y;\n",
        "\tfor(y = 0; y < YDIM; y++)\n",
        "\t{\n",
        "\t\tprintf(\"\\n\");\n",
        "\t\tfor(x = 0; x < XDIM; x++)\n",
        "\t\t{\n",
        "\t\t    printf(\"%i \", *(ap + (y*XDIM) + x));\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"\\n\");\n",
        "return 0;\n",
        "}\n",
        "\n",
        "\n",
        "/******************************************************************************\n",
        " * Host main routine\n",
        " */\n",
        "int main(int argc, char *argv[])\n",
        "{   int i, v=0;\n",
        "    int blocksPerGrid, threadsPerBlock;\n",
        "    blocksPerGrid = BLOCKSPERGRID;\n",
        "    // Error code to check return values for CUDA calls\n",
        "    cudaError_t err = cudaSuccess;\n",
        "\n",
        "    // Print the vector length to be used, and compute its size\n",
        "    int numElements = MATRIXSIZE;\n",
        "    size_t size = MATRIXSIZE * sizeof(int);\n",
        "    if(v == 1) printf(\"[Matrix mult of %d elements]\\n\", numElements);\n",
        "\n",
        "    // Allocate the host input vector A\n",
        "    int *h_A = (int *)malloc(size);\n",
        "\n",
        "    // Allocate the host input vector B\n",
        "    int *h_B = (int *)malloc(size);\n",
        "\n",
        "    // Allocate the host output vector C\n",
        "    int *h_C = (int *)malloc(size);\n",
        "\n",
        "    // Verify that allocations succeeded\n",
        "    if (h_A == NULL || h_B == NULL || h_C == NULL)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Initialize the host input vectors\n",
        "    \n",
        "    for(i = 0; i < MATRIXSIZE; i++){\n",
        "        *(h_A + i) = rand() & 0xF;\n",
        "        *(h_B + i) = rand() & 0xF;        \n",
        "        *(h_C + i) = 0;\n",
        "    }\n",
        "    //printMatrix(h_A);\n",
        "    //printMatrix(h_B);\n",
        "    \n",
        "    // Allocate the device input vector A\n",
        "    int *d_A = NULL;\n",
        "    err = cudaMalloc((void **)&d_A, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Allocate the device input vector B\n",
        "    int *d_B = NULL;\n",
        "    err = cudaMalloc((void **)&d_B, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Allocate the device output vector C\n",
        "    int *d_C = NULL;\n",
        "    err = cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "    \n",
        "\n",
        "    // Copy the host input vectors A and B in host memory to the device input vectors in\n",
        "    // device memory\n",
        "    if(v == 1) printf(\"Copy input data from the host memory to the CUDA device\\n\");\n",
        "    err = cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector A from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    err = cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector B from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Launch the Vector Add CUDA Kernel\n",
        "    threadsPerBlock = NUMTHREADS/blocksPerGrid;\n",
        "    //blocksPerGrid = BLOCKS; //(numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock);\n",
        "    multMatrix<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);\n",
        "    err = cudaGetLastError();\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to launch vectorAdd kernel (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Copy the device result vector in device memory to the host result vector\n",
        "    // in host memory.\n",
        "\n",
        "    err = cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "\n",
        "    // Free device global memory\n",
        "    err = cudaFree(d_A);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    err = cudaFree(d_B);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector B (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    err = cudaFree(d_C);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    printMatrix(h_C);\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    // Reset the device and exit\n",
        "    // cudaDeviceReset causes the driver to clean up all state. While\n",
        "    // not mandatory in normal operation, it is good practice.  It is also\n",
        "    // needed to ensure correct operation when the application is being\n",
        "    // profiled. Calling cudaDeviceReset causes all profile data to be\n",
        "    // flushed before the application exits\n",
        "    err = cudaDeviceReset();\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to deinitialize the device! error=%s\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DYCiZiySmo4",
        "cellView": "form"
      },
      "source": [
        "#@title pipeline memory\n",
        "\n",
        "%%cu\n",
        "#include <stdio.h>\n",
        "// For the CUDA runtime routines (prefixed with \"cuda_\")\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define NUMELEMENTS 100e06\n",
        "  \n",
        "/*******************************************************************************/\n",
        "\n",
        "__global__ void\n",
        "pipeMemory(const float *A, float *C, int numElements)\n",
        "{\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "/*******************************************************************************/\n",
        "int main(void)\n",
        "{\n",
        "    // Error code to check return values for CUDA calls\n",
        "    cudaError_t err = cudaSuccess;\n",
        "\n",
        "    // Print the vector length to be used, and compute its size\n",
        "    int numElements = NUMELEMENTS;\n",
        "    size_t size = numElements * sizeof(float);\n",
        "    printf(\"[Vector addition of %d elements]\\n\", numElements);\n",
        "\n",
        "    // Allocate the host input vector A\n",
        "    float *h_A = (float *)malloc(size);\n",
        "\n",
        "    // Allocate the host output vector C\n",
        "    float *h_C = (float *)malloc(size);\n",
        "\n",
        "    // Verify that allocations succeeded\n",
        "    if (h_A == NULL || h_C == NULL)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate host vectors!\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Initialize the host input vectors\n",
        "    for (int i = 0; i < numElements; ++i)\n",
        "    {\n",
        "        h_A[i] = rand()/(float)RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Allocate the device input vector A\n",
        "    float *d_A = NULL;\n",
        "    err = cudaMalloc((void **)&d_A, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "\n",
        "    // Allocate the device output vector C\n",
        "    float *d_C = NULL;\n",
        "    err = cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to allocate device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Copy the host input vectors A and B in host memory to the device input vectors in\n",
        "    // device memory\n",
        "    printf(\"Copy input data from the host memory to the CUDA device\\n\");\n",
        "    err = cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector A from host to device (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Launch the Vector Add CUDA Kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid =(numElements + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    printf(\"CUDA kernel launch with %d blocks of %d threads\\n\", blocksPerGrid, threadsPerBlock);\n",
        "    pipeMemory<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_C, numElements);\n",
        "    err = cudaGetLastError();\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to launch vectorAdd kernel (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Copy the device result vector in device memory to the host result vector\n",
        "    // in host memory.\n",
        "    printf(\"Copy output data from the CUDA device to the host memory\\n\");\n",
        "    err = cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to copy vector C from device to host (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Free device global memory\n",
        "    err = cudaFree(d_A);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector A (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    err = cudaFree(d_C);\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to free device vector C (error code %s)!\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    // Free host memory\n",
        "    free(h_A);\n",
        "    free(h_C);\n",
        "\n",
        "    // Reset the device and exit\n",
        "    err = cudaDeviceReset();\n",
        "\n",
        "    if (err != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"Failed to deinitialize the device! error=%s\\n\", cudaGetErrorString(err));\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    printf(\"Done\\n\");\n",
        "    return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6li71d6Hxdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b160ed-462d-49ef-b81b-b95106af2225"
      },
      "source": [
        "%cd /usr/local/cuda-10.1/samples/0_Simple/vectorAdd/\n",
        "!make\n",
        "!nvprof ./vectorAdd\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-10.1/samples/0_Simple/vectorAdd\n",
            "make: Nothing to be done for 'all'.\n",
            "[Vector addition of 50000 elements]\n",
            "==280== NVPROF is profiling process 280, command: ./vectorAdd\n",
            "Copy input data from the host memory to the CUDA device\n",
            "CUDA kernel launch with 196 blocks of 256 threads\n",
            "Copy output data from the CUDA device to the host memory\n",
            "Test PASSED\n",
            "Done\n",
            "==280== Profiling application: ./vectorAdd\n",
            "==280== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   64.30%  38.622us         2  19.311us  19.135us  19.487us  [CUDA memcpy HtoD]\n",
            "                   28.40%  17.055us         1  17.055us  17.055us  17.055us  [CUDA memcpy DtoH]\n",
            "                    7.30%  4.3840us         1  4.3840us  4.3840us  4.3840us  vectorAdd(float const *, float const *, float*, int)\n",
            "      API calls:   99.43%  197.46ms         3  65.820ms  6.2250us  197.45ms  cudaMalloc\n",
            "                    0.21%  408.64us         1  408.64us  408.64us  408.64us  cuDeviceTotalMem\n",
            "                    0.17%  340.48us         3  113.49us  72.254us  194.00us  cudaMemcpy\n",
            "                    0.08%  157.95us        97  1.6280us     153ns  73.614us  cuDeviceGetAttribute\n",
            "                    0.07%  140.31us         3  46.768us  7.8110us  107.89us  cudaFree\n",
            "                    0.02%  40.331us         1  40.331us  40.331us  40.331us  cudaLaunchKernel\n",
            "                    0.02%  31.244us         1  31.244us  31.244us  31.244us  cuDeviceGetName\n",
            "                    0.00%  3.9510us         1  3.9510us  3.9510us  3.9510us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.2620us         3     754ns     171ns  1.6320us  cuDeviceGetCount\n",
            "                    0.00%  1.4310us         2     715ns     376ns  1.0550us  cuDeviceGet\n",
            "                    0.00%     367ns         1     367ns     367ns     367ns  cuDeviceGetUuid\n",
            "                    0.00%     356ns         1     356ns     356ns     356ns  cudaGetLastError\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_d0CjOFHvHF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gxx_gENHrUM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}